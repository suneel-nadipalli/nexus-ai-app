{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import openai\n",
    "\n",
    "import langchain\n",
    "\n",
    "import langchain.document_loaders\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from config.ini file\n",
    "\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read('../../config/config.ini')\n",
    "\n",
    "SECRETS = config['SECRETS']\n",
    "\n",
    "# set openai api key\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = SECRETS['openapi_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(file_path):\n",
    "    \n",
    "    loader = PyPDFLoader(file_path)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectordb(chunks, CHROMA_PATH):\n",
    "\n",
    "    CHROMA_PATH = f\"../../data/chroma/{CHROMA_PATH}\"\n",
    "\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        db = Chroma(persist_directory=CHROMA_PATH, embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "    else:\n",
    "        db = Chroma.from_documents(\n",
    "            chunks, OpenAIEmbeddings(), persist_directory=CHROMA_PATH\n",
    "        )\n",
    "\n",
    "        db.persist()\n",
    "\n",
    "        print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sample(chunk, db):\n",
    "\n",
    "    PROMPT_TEMPLATE = \"\"\"\n",
    "    Answer the question based only on the following context:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    ---\n",
    "\n",
    "    Answer the question based on the above context: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    query_text = f\"\"\"\n",
    "\n",
    "    Classify whether the given chunk involves a decision that will effect the story or not.\n",
    "\n",
    "    A decision is defined as when the character goes about making a choice between two or more options. \n",
    "    The decision should be significant enough to affect the story in a major way.\n",
    "    It doesn't really involve emotions, feelings or thoughts, but what the character does, or what happens to them.\n",
    "    This involes interactions between characters, or the character and the environment.\n",
    "    What isn't a decision is chunks describing the setting, or the character's thoughts or feelings.\n",
    "\n",
    "    Generate response in a JSON with the following keys: [\"decision\", \"text\", \"description\"]\n",
    "\n",
    "    decision: \"yes\"/\"no\"\n",
    "    text: the chunk being passed in\n",
    "    description: what the decision is\n",
    "\n",
    "    ```{chunk.page_content}```\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    results = db.similarity_search_with_relevance_scores(query_text, k=5)\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "\n",
    "    model = ChatOpenAI()\n",
    "    response_text = model.predict(prompt)\n",
    "\n",
    "    return eval(response_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dune'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = \"../../data/pdf\"\n",
    "\n",
    "samples = []\n",
    "\n",
    "pdfs = os.listdir(base_path)\n",
    "\n",
    "pdf_path = f\"{base_path}/{pdfs[0]}\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "Path(pdf_path).stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dune.pdf... 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Me\\Duke\\Classes\\Spring '24\\AIPI 540 - Deep Learning\\Individual Project\\workspace\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "  0%|          | 0/715 [00:00<?, ?it/s]c:\\Me\\Duke\\Classes\\Spring '24\\AIPI 540 - Deep Learning\\Individual Project\\workspace\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "c:\\Me\\Duke\\Classes\\Spring '24\\AIPI 540 - Deep Learning\\Individual Project\\workspace\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "100%|██████████| 715/715 [1:14:18<00:00,  6.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Processing eg.pdf... 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:51:53<00:00,  6.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Processing gr.pdf... 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [2:13:51<00:00,  8.03s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Processing in_mb.pdf... 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:48:51<00:00,  6.53s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Processing in_rm.pdf... 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:56:37<00:00,  7.00s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Processing in_rm_2.pdf... 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:23:40<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Processing kgf.pdf... 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:52<00:00,  7.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Processing khaleja.pdf... 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397/397 [33:16<00:00,  5.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Processing nr.pdf... 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:30:23<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Processing pokiri.pdf... 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [24:06<00:00,  4.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "base_path = \"../../data/pdf\"\n",
    "\n",
    "samples = []\n",
    "\n",
    "pdfs = os.listdir(base_path)\n",
    "\n",
    "for pdf in pdfs:\n",
    "\n",
    "    print(f\"Processing {pdf}... {pdfs.index(pdf)}/{len(pdfs)}\")\n",
    "    \n",
    "    pdf_path = f\"{base_path}/{pdf}\"\n",
    "\n",
    "    CHROMA_PATH = pdf_path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    chunks = get_chunks(pdf_path)\n",
    "\n",
    "    # print(f\"Found {len(chunks)} chunks in {pdf_path}.\")\n",
    "\n",
    "    db = get_vectordb(chunks, CHROMA_PATH)\n",
    "\n",
    "    try:\n",
    "\n",
    "        chunks = random.sample(chunks, 1000)\n",
    "    \n",
    "    except:\n",
    "        chunks = chunks\n",
    "\n",
    "    for chunk in tqdm(chunks):\n",
    "\n",
    "        try:\n",
    "\n",
    "            sample = gen_sample(chunk, db)\n",
    "\n",
    "            sample['source'] = Path(pdf_path).stem\n",
    "\n",
    "            samples.append(sample)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{'-----'*50}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6272"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dec_df = pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>text</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>massive mining vehicle, a HARVESTER, kicking u...</td>\n",
       "      <td>This chunk describes the setting and actions o...</td>\n",
       "      <td>dune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>being hauled by a powerful CARRYALL. ON THE GR...</td>\n",
       "      <td>This chunk describes the setting and actions o...</td>\n",
       "      <td>dune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>SPICE VISION: EXT. ARRAKIS - DESERT - DAY 95C ...</td>\n",
       "      <td>This chunk describes a vision of the future an...</td>\n",
       "      <td>dune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>strange MISSLE LAUNCHER, one of multiple cloth...</td>\n",
       "      <td>This chunk describes the setting and the chara...</td>\n",
       "      <td>dune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>Flickering Fremen PLASMA LASERS lance up at th...</td>\n",
       "      <td>This chunk describes action scenes involving t...</td>\n",
       "      <td>dune</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  decision                                               text  \\\n",
       "0       no  massive mining vehicle, a HARVESTER, kicking u...   \n",
       "1       no  being hauled by a powerful CARRYALL. ON THE GR...   \n",
       "2       no  SPICE VISION: EXT. ARRAKIS - DESERT - DAY 95C ...   \n",
       "3       no  strange MISSLE LAUNCHER, one of multiple cloth...   \n",
       "4       no  Flickering Fremen PLASMA LASERS lance up at th...   \n",
       "\n",
       "                                         description source  \n",
       "0  This chunk describes the setting and actions o...   dune  \n",
       "1  This chunk describes the setting and actions o...   dune  \n",
       "2  This chunk describes a vision of the future an...   dune  \n",
       "3  This chunk describes the setting and the chara...   dune  \n",
       "4  This chunk describes action scenes involving t...   dune  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decision\n",
       "no     5132\n",
       "yes    1140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_df['decision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_df.to_csv(\"../../data/output/decisions_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
